{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e5e895b-b29e-4c05-8c8c-5cfd28883798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "7\n",
      "Graph(num_nodes=2708, num_edges=10556,\n",
      "      ndata_schemes={'train_mask': Scheme(shape=(), dtype=torch.bool), 'label': Scheme(shape=(), dtype=torch.int64), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool), 'feat': Scheme(shape=(1433,), dtype=torch.float32)}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import dgl\n",
    "from dgl import DGLGraph\n",
    "from dgl.data import CitationGraphDataset\n",
    "\n",
    "dataset = CitationGraphDataset('cora')\n",
    "g = dataset[0]\n",
    "\n",
    "print(dataset.num_classes)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0529f4f7-f96d-4415-abd0-b20e47e98174",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = dataset.num_classes\n",
    "\n",
    "train_mask = g.ndata['train_mask']\n",
    "val_mask = g.ndata['val_mask']\n",
    "test_mask = g.ndata['test_mask']\n",
    "labels = g.ndata['label']\n",
    "features = g.ndata['feat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce7907ba-1b97-4aca-8a5e-b7c19009bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, g, in_dim, out_dim):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.g = g\n",
    "        self.fc = nn.Linear(in_dim, out_dim, bias = False)\n",
    "        self.attn_fc = nn.Linear(2 * out_dim, 1, bias = False)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_normal_(self.fc.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.attn_fc.weight, gain=gain)\n",
    "        \n",
    "    def edge_attention(self, edges):\n",
    "        z2 = torch.cat([edges.src['z'], edges.dst['z']], dim = 1)\n",
    "        a = self.attn_fc(z2)\n",
    "        return {'e': F.leaky_relu(a)}\n",
    "    \n",
    "    def message_func(self, edges):\n",
    "        return {'z': edges.src['z'], 'e': edges.data['e']}\n",
    "    \n",
    "    def reduce_func(self, nodes):\n",
    "        alpha = F.softmax(nodes.mailbox['e'], dim = 1)\n",
    "        h = torch.sum(alpha * nodes.mailbox['z'], dim = 1)\n",
    "        return {'h': h}\n",
    "    \n",
    "    def forward(self, h):\n",
    "        z = self.fc(h)\n",
    "        self.g.ndata['z'] = z\n",
    "        self.g.apply_edges(self.edge_attention)\n",
    "        self.g.update_all(self.message_func, self.reduce_func)\n",
    "        return self.g.ndata.pop('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f608f89-f33a-4729-845b-7c106df4873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadGATLayer(nn.Module):\n",
    "    def __init__(self, g, in_dim, out_dim, num_heads, merge = 'cat'):\n",
    "        super(MultiHeadGATLayer, self).__init__()\n",
    "        self.heads = nn.ModuleList()\n",
    "        for i in range(num_heads):\n",
    "            self.heads.append(GATLayer(g, in_dim, out_dim))\n",
    "        self.merge = merge\n",
    "    \n",
    "    def forward(self, h):\n",
    "        head_outs = [attn_head(h) for attn_head in self.heads]\n",
    "        if self.merge == 'cat':\n",
    "            return torch.cat(head_outs, dim = 1)\n",
    "        else:\n",
    "            return torch.mean(torch.stack(head_outs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d5f2547-8f58-4574-8428-471645036e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(nn.Module):\n",
    "    def __init__(self, g, in_dim, hidden_dim, out_dim, num_heads):\n",
    "        super(GAT, self).__init__()\n",
    "        self.layer1 = MultiHeadGATLayer(g, in_dim, hidden_dim, num_heads)\n",
    "        self.layer2 = MultiHeadGATLayer(g, hidden_dim * num_heads, out_dim, 1)\n",
    "        \n",
    "    def forward(self, h):\n",
    "        h = self.layer1(h)\n",
    "        h = F.elu(h)\n",
    "        h = self.layer2(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5807f96d-3f22-41f4-90b1-02a88905fd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT(\n",
      "  (layer1): MultiHeadGATLayer(\n",
      "    (heads): ModuleList(\n",
      "      (0): GATLayer(\n",
      "        (fc): Linear(in_features=1433, out_features=8, bias=False)\n",
      "        (attn_fc): Linear(in_features=16, out_features=1, bias=False)\n",
      "      )\n",
      "      (1): GATLayer(\n",
      "        (fc): Linear(in_features=1433, out_features=8, bias=False)\n",
      "        (attn_fc): Linear(in_features=16, out_features=1, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): MultiHeadGATLayer(\n",
      "    (heads): ModuleList(\n",
      "      (0): GATLayer(\n",
      "        (fc): Linear(in_features=16, out_features=8, bias=False)\n",
      "        (attn_fc): Linear(in_features=16, out_features=1, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = GAT(g, \n",
    "            in_dim = features.size()[1], \n",
    "            hidden_dim = 8, \n",
    "            out_dim = 8, \n",
    "            num_heads = 2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6897d9c9-899d-4a18-b82b-802062c459b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000  /  Loss 2.0797  /  Train_acc 0.1214  /  Time(s) nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hobbit\\anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\Hobbit\\anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00010  /  Loss 2.0712  /  Train_acc 0.9214  /  Time(s) 0.0858\n",
      "Epoch 00020  /  Loss 2.0616  /  Train_acc 0.9571  /  Time(s) 0.0890\n",
      "Epoch 00030  /  Loss 2.0506  /  Train_acc 0.9571  /  Time(s) 0.0887\n",
      "Epoch 00040  /  Loss 2.0378  /  Train_acc 0.9643  /  Time(s) 0.0895\n",
      "Epoch 00050  /  Loss 2.0230  /  Train_acc 0.9643  /  Time(s) 0.0909\n",
      "Epoch 00060  /  Loss 2.0062  /  Train_acc 0.9643  /  Time(s) 0.0903\n",
      "Epoch 00070  /  Loss 1.9872  /  Train_acc 0.9643  /  Time(s) 0.0899\n",
      "Epoch 00080  /  Loss 1.9659  /  Train_acc 0.9643  /  Time(s) 0.0898\n",
      "Epoch 00090  /  Loss 1.9424  /  Train_acc 0.9571  /  Time(s) 0.0895\n",
      "Epoch 00100  /  Loss 1.9167  /  Train_acc 0.9571  /  Time(s) 0.0892\n",
      "Epoch 00110  /  Loss 1.8888  /  Train_acc 0.9571  /  Time(s) 0.0891\n",
      "Epoch 00120  /  Loss 1.8587  /  Train_acc 0.9571  /  Time(s) 0.0890\n",
      "Epoch 00130  /  Loss 1.8265  /  Train_acc 0.9571  /  Time(s) 0.0889\n",
      "Epoch 00140  /  Loss 1.7923  /  Train_acc 0.9571  /  Time(s) 0.0887\n",
      "Epoch 00150  /  Loss 1.7562  /  Train_acc 0.9571  /  Time(s) 0.0886\n",
      "Epoch 00160  /  Loss 1.7182  /  Train_acc 0.9643  /  Time(s) 0.0887\n",
      "Epoch 00170  /  Loss 1.6785  /  Train_acc 0.9643  /  Time(s) 0.0886\n",
      "Epoch 00180  /  Loss 1.6371  /  Train_acc 0.9643  /  Time(s) 0.0887\n",
      "Epoch 00190  /  Loss 1.5941  /  Train_acc 0.9714  /  Time(s) 0.0888\n"
     ]
    }
   ],
   "source": [
    "dur = []\n",
    "\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    if epoch >= 3:\n",
    "        t0 = time.time()\n",
    "\n",
    "    out = model(features)\n",
    "    loss = criterion(out[train_mask], labels[train_mask])\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch >= 3:\n",
    "        dur.append(time.time() - t0)\n",
    "\n",
    "#     _, indices = torch.max(out[train_mask], dim=1)\n",
    "#     correct = torch.sum(indices == labels[train_mask])\n",
    "#     train_acc = correct.item() / len(labels[train_mask])\n",
    "    \n",
    "    pred = out.argmax(1)\n",
    "    train_correct = (pred[train_mask] == labels[train_mask]).sum().item()\n",
    "    train_acc = train_correct / len(labels[train_mask])\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch {:05d}  /  Loss {:.4f}  /  Train_acc {:.4f}  /  Time(s) {:.4f}\".\n",
    "              format(epoch, loss.item(), train_acc, np.mean(dur)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe6db967-8e74-4d3b-a9af-5ef31b5fe03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy 0.7260\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "out = model(features)\n",
    "pred = out.argmax(1)\n",
    "\n",
    "test_correct = (pred[test_mask] == labels[test_mask]).sum().item()\n",
    "test_acc = test_correct / len(labels[test_mask])\n",
    "print(\"Test Accuracy {:.4f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d4cca3-751d-422e-83ab-10c141756e03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
