{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6fce801-50a2-4615-be83-8b225f64f8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "7\n",
      "Graph(num_nodes=2708, num_edges=10556,\n",
      "      ndata_schemes={'train_mask': Scheme(shape=(), dtype=torch.bool), 'label': Scheme(shape=(), dtype=torch.int64), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool), 'feat': Scheme(shape=(1433,), dtype=torch.float32)}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "from dgl.data import register_data_args\n",
    "from dgl.data import CitationGraphDataset\n",
    "# from dgl.data import CoraGraphDataset, CiteseerGraphDataset\n",
    "\n",
    "dataset = CitationGraphDataset('cora')\n",
    "# dataset = CoraGraphDataset()\n",
    "g = dataset[0]\n",
    "\n",
    "print(dataset.num_classes)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df872a45-25c9-4c80-8e7b-abe7b6a3be50",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = dataset.num_classes\n",
    "\n",
    "train_mask = g.ndata['train_mask']\n",
    "val_mask = g.ndata['val_mask']\n",
    "test_mask = g.ndata['test_mask']\n",
    "labels = g.ndata['label']\n",
    "features = g.ndata['feat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1159da2c-fffa-4a54-8aa8-f11ee32b3349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dgl.nn import GATConv\n",
    "\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self,\n",
    "                 g,\n",
    "                 num_layers,\n",
    "                 in_dim,\n",
    "                 num_hidden,\n",
    "                 num_classes,\n",
    "                 heads,\n",
    "                 activation,\n",
    "                 feat_drop,\n",
    "                 attn_drop,\n",
    "                 negative_slope,\n",
    "                 residual):\n",
    "        super(GAT, self).__init__()\n",
    "        self.g = g\n",
    "        self.num_layers = num_layers\n",
    "        self.gat_layers = nn.ModuleList()\n",
    "        self.activation = activation\n",
    "        \n",
    "        # input projection (no residual)\n",
    "        self.gat_layers.append(GATConv(\n",
    "            in_dim, num_hidden, heads[0],\n",
    "            feat_drop, attn_drop, negative_slope, False, self.activation))\n",
    "        \n",
    "        # hidden layers\n",
    "        for l in range(1, num_layers):\n",
    "            # due to multi-head, the in_dim = num_hidden * num_heads\n",
    "            self.gat_layers.append(GATConv(\n",
    "                num_hidden * heads[l-1], num_hidden, heads[l],\n",
    "                feat_drop, attn_drop, negative_slope, residual, self.activation))\n",
    "        \n",
    "        # output projection\n",
    "        self.gat_layers.append(GATConv(\n",
    "            num_hidden * heads[-2], num_classes, heads[-1],\n",
    "            feat_drop, attn_drop, negative_slope, residual, None))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        h = inputs\n",
    "        for l in range(self.num_layers):\n",
    "            h = self.gat_layers[l](self.g, h).flatten(1)\n",
    "        # output projection\n",
    "        logits = self.gat_layers[-1](self.g, h).mean(1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d39e20b0-affd-47e3-b6c5-2abcb484192f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93886c23-f12b-4763-861d-9fb1d6f93276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_heads = 8\n",
    "num_out_heads = 1\n",
    "num_layers = 1\n",
    "\n",
    "heads = ([num_heads] * num_layers) + [num_out_heads]\n",
    "heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d07c7f7-5634-49e9-b47c-830c71f1bf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT(\n",
      "  (gat_layers): ModuleList(\n",
      "    (0): GATConv(\n",
      "      (fc): Linear(in_features=1433, out_features=64, bias=False)\n",
      "      (feat_drop): Dropout(p=0.6, inplace=False)\n",
      "      (attn_drop): Dropout(p=0.6, inplace=False)\n",
      "      (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (1): GATConv(\n",
      "      (fc): Linear(in_features=64, out_features=7, bias=False)\n",
      "      (feat_drop): Dropout(p=0.6, inplace=False)\n",
      "      (attn_drop): Dropout(p=0.6, inplace=False)\n",
      "      (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = GAT(g,\n",
    "            in_dim = features.shape[1],\n",
    "            num_classes = n_classes,\n",
    "            heads = heads,\n",
    "            activation = F.elu,\n",
    "            num_layers = 1,\n",
    "            num_hidden = 8,\n",
    "            feat_drop = 0.6,\n",
    "            attn_drop = 0.6,\n",
    "            negative_slope = 0.2,\n",
    "            residual = False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.005, weight_decay = 5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "743e1f43-53b9-435b-8833-a66e123387b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, features, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(features)\n",
    "        out = out[mask]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "254c84b3-4ac7-4fe5-af62-2fc6aba405ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Time(s) nan | Loss 1.9445 | TrainAcc 0.1000 | ValAcc 0.2140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hobbit\\anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\Hobbit\\anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00010 | Time(s) 0.1063 | Loss 1.8741 | TrainAcc 0.5000 | ValAcc 0.6920\n",
      "Epoch 00020 | Time(s) 0.1070 | Loss 1.8062 | TrainAcc 0.5643 | ValAcc 0.6320\n",
      "Epoch 00030 | Time(s) 0.1074 | Loss 1.7147 | TrainAcc 0.6500 | ValAcc 0.7860\n",
      "Epoch 00040 | Time(s) 0.1083 | Loss 1.5846 | TrainAcc 0.6929 | ValAcc 0.7560\n",
      "Epoch 00050 | Time(s) 0.1095 | Loss 1.4498 | TrainAcc 0.6929 | ValAcc 0.7880\n",
      "Epoch 00060 | Time(s) 0.1105 | Loss 1.4195 | TrainAcc 0.6643 | ValAcc 0.7940\n",
      "Epoch 00070 | Time(s) 0.1115 | Loss 1.3081 | TrainAcc 0.7000 | ValAcc 0.8020\n",
      "Epoch 00080 | Time(s) 0.1119 | Loss 1.2070 | TrainAcc 0.7214 | ValAcc 0.7900\n",
      "Epoch 00090 | Time(s) 0.1124 | Loss 1.1139 | TrainAcc 0.7143 | ValAcc 0.7920\n",
      "Epoch 00100 | Time(s) 0.1129 | Loss 1.1664 | TrainAcc 0.7357 | ValAcc 0.8000\n",
      "Epoch 00110 | Time(s) 0.1132 | Loss 1.0778 | TrainAcc 0.7214 | ValAcc 0.7960\n",
      "Epoch 00120 | Time(s) 0.1136 | Loss 1.0406 | TrainAcc 0.6714 | ValAcc 0.8000\n",
      "Epoch 00130 | Time(s) 0.1141 | Loss 0.9896 | TrainAcc 0.7000 | ValAcc 0.8000\n",
      "Epoch 00140 | Time(s) 0.1144 | Loss 0.9783 | TrainAcc 0.7500 | ValAcc 0.7960\n",
      "Epoch 00150 | Time(s) 0.1146 | Loss 0.8740 | TrainAcc 0.8143 | ValAcc 0.7980\n",
      "Epoch 00160 | Time(s) 0.1148 | Loss 1.0197 | TrainAcc 0.7143 | ValAcc 0.8040\n",
      "Epoch 00170 | Time(s) 0.1149 | Loss 0.8728 | TrainAcc 0.7429 | ValAcc 0.8000\n",
      "Epoch 00180 | Time(s) 0.1153 | Loss 0.8608 | TrainAcc 0.7000 | ValAcc 0.7880\n",
      "Epoch 00190 | Time(s) 0.1155 | Loss 0.9703 | TrainAcc 0.7071 | ValAcc 0.7880\n"
     ]
    }
   ],
   "source": [
    "dur = []\n",
    "\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    \n",
    "    if epoch >= 3:\n",
    "        t0 = time.time()\n",
    "        \n",
    "    out = model(features)\n",
    "    loss = criterion(out[train_mask], labels[train_mask])\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch >= 3:\n",
    "        dur.append(time.time() - t0)\n",
    "       \n",
    "    pred = out.argmax(1)\n",
    "    train_correct = (pred[train_mask] == labels[train_mask]).sum().item()\n",
    "    train_acc = train_correct / len(labels[train_mask])\n",
    "\n",
    "    # val_acc = evaluate(model, features, labels, val_mask)\n",
    "    val_out = evaluate(model, features, val_mask)\n",
    "    val_correct = (val_out.argmax(1) == labels[val_mask]).sum().item()\n",
    "    val_acc = val_correct / len(labels[val_mask])\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | TrainAcc {:.4f} | ValAcc {:.4f}\".\n",
    "          format(epoch, np.mean(dur), loss.item(), train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08606929-b5e5-449e-8a92-b4d5ad4a2f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy 0.8130\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "out = model(features)\n",
    "pred = out.argmax(1)\n",
    "test_correct = (pred[test_mask] == labels[test_mask]).sum().item()\n",
    "test_acc = test_correct / len(labels[test_mask])\n",
    "print(\"Test Accuracy {:.4f}\".format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
